{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8cd09d-4891-45f3-a4d5-cd5b7fa8adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1460, 81)\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "5   6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
      "6   7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
      "7   8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
      "8   9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
      "9  10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
      "0         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "2         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "3         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "4         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "5         Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n",
      "6         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "7         Lvl    AllPub  ...        0    NaN    NaN        Shed     350   \n",
      "8         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "9         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "\n",
      "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0      2   2008        WD         Normal     208500  \n",
      "1      5   2007        WD         Normal     181500  \n",
      "2      9   2008        WD         Normal     223500  \n",
      "3      2   2006        WD        Abnorml     140000  \n",
      "4     12   2008        WD         Normal     250000  \n",
      "5     10   2009        WD         Normal     143000  \n",
      "6      8   2007        WD         Normal     307000  \n",
      "7     11   2009        WD         Normal     200000  \n",
      "8      4   2008        WD        Abnorml     129900  \n",
      "9      1   2008        WD         Normal     118000  \n",
      "\n",
      "[10 rows x 81 columns]\n",
      "\n",
      "SalePrice descriptive stats:\n",
      "count      1460.000000\n",
      "mean     180921.195890\n",
      "std       79442.502883\n",
      "min       34900.000000\n",
      "25%      129975.000000\n",
      "50%      163000.000000\n",
      "75%      214000.000000\n",
      "max      755000.000000\n",
      "Name: SalePrice, dtype: float64\n",
      "\n",
      "Subset head:\n",
      "   GrLivArea  TotalBsmtSF Neighborhood HouseStyle  SalePrice\n",
      "0       1710          856      CollgCr     2Story     208500\n",
      "1       1262         1262      Veenker     1Story     181500\n",
      "2       1786          920      CollgCr     2Story     223500\n",
      "3       1717          756      Crawfor     2Story     140000\n",
      "4       2198         1145      NoRidge     2Story     250000\n",
      "5       1362          796      Mitchel     1.5Fin     143000\n",
      "6       1694         1686      Somerst     1Story     307000\n",
      "7       2090         1107       NWAmes     2Story     200000\n",
      "8       1774          952      OldTown     1.5Fin     129900\n",
      "9       1077          991      BrkSide     1.5Unf     118000\n",
      "\n",
      "Train shape: (1168, 4) Val shape: (292, 4)\n",
      "\n",
      "Processed feature matrix shapes (train, val): (1168, 33) (292, 33)\n",
      "\n",
      "Model trained and saved to models/\n",
      "Validation RMSLE: 0.1912\n",
      "\n",
      "Comparison (first 10 rows of validation set):\n",
      "   y_true    y_pred\n",
      "0  154500  138489.0\n",
      "1  325000  302919.0\n",
      "2  115000  101007.0\n",
      "3  159000  144296.0\n",
      "4  315500  235169.0\n",
      "5   75500   83491.0\n",
      "6  311500  194323.0\n",
      "7  146000  144726.0\n",
      "8   84500   83491.0\n",
      "9  135500  114299.0\n",
      "Saved submission.csv (first 5 lines):\n",
      "     Id      SalePrice\n",
      "0  1461  117516.056377\n",
      "1  1462  152088.466667\n",
      "2  1463  179805.955955\n",
      "3  1464  181029.960987\n",
      "4  1465  186167.838619\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import joblib\n",
    "\n",
    "def compute_rmsle(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 4) -> float:\n",
    "    \n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    return round(rmsle, precision)\n",
    "    \n",
    "BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) if \"__file__\" in globals() else os.path.abspath(\"..\")\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, \"train.csv\")\n",
    "TEST_PATH = os.path.join(DATA_DIR, \"test.csv\")\n",
    "\n",
    "df = pd.read_csv(TRAIN_PATH)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head(10))\n",
    "\n",
    "\n",
    "print('\\nSalePrice descriptive stats:')\n",
    "print(df['SalePrice'].describe())\n",
    "\n",
    "CONTINUOUS = ['GrLivArea', 'TotalBsmtSF']\n",
    "CATEGORICAL = ['Neighborhood', 'HouseStyle']\n",
    "REQUIRED_COLUMNS = CONTINUOUS + CATEGORICAL + ['SalePrice']\n",
    "\n",
    "missing_cols = [c for c in REQUIRED_COLUMNS if c not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Required columns missing from dataset: {missing_cols}. Please pick other features or check dataset.\")\n",
    "\n",
    "df_sub = df[REQUIRED_COLUMNS].copy()\n",
    "\n",
    "print('\\nSubset head:')\n",
    "print(df_sub.head(10))\n",
    "\n",
    "for col in CONTINUOUS:\n",
    "    if df_sub[col].isna().sum() > 0:\n",
    "        med = df_sub[col].median()\n",
    "        df_sub[col] = df_sub[col].fillna(med)\n",
    "\n",
    "for col in CATEGORICAL:\n",
    "    if df_sub[col].isna().sum() > 0:\n",
    "        mode = df_sub[col].mode()[0]\n",
    "        df_sub[col] = df_sub[col].fillna(mode)\n",
    "\n",
    "X = df_sub.drop(columns=['SalePrice'])\n",
    "y = df_sub['SalePrice'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('\\nTrain shape:', X_train.shape, 'Val shape:', X_val.shape)\n",
    "\n",
    "X_train_cat = pd.get_dummies(X_train[CATEGORICAL], drop_first=True)\n",
    "X_val_cat = pd.get_dummies(X_val[CATEGORICAL], drop_first=True)\n",
    "\n",
    "X_train_cat, X_val_cat = X_train_cat.align(X_val_cat, join='left', axis=1, fill_value=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_cont = scaler.fit_transform(X_train[CONTINUOUS])\n",
    "X_val_cont = scaler.transform(X_val[CONTINUOUS])\n",
    "\n",
    "X_train_proc = np.hstack([X_train_cont, X_train_cat.values])\n",
    "X_val_proc = np.hstack([X_val_cont, X_val_cat.values])\n",
    "\n",
    "print('\\nProcessed feature matrix shapes (train, val):', X_train_proc.shape, X_val_proc.shape)\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_val_log = np.log1p(y_val)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train_proc, y_train_log)\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(model, 'models/rf_log_target.joblib')\n",
    "joblib.dump(scaler, 'models/standard_scaler.joblib')\n",
    "cat_columns = list(X_train_cat.columns)\n",
    "joblib.dump(cat_columns, 'models/cat_columns.joblib')\n",
    "\n",
    "print('\\nModel trained and saved to models/')\n",
    "\n",
    "y_val_log_pred = model.predict(X_val_proc)\n",
    "\n",
    "y_val_pred = np.expm1(y_val_log_pred)\n",
    "\n",
    "y_val_pred = np.clip(y_val_pred, a_min=0, a_max=None)\n",
    "\n",
    "rmsle_val = compute_rmsle(y_test=y_val, y_pred=y_val_pred, precision=4)\n",
    "print(f\"Validation RMSLE: {rmsle_val}\")\n",
    "\n",
    "comp = pd.DataFrame({\n",
    "    'y_true': y_val[:10],\n",
    "    'y_pred': np.round(y_val_pred[:10], 0)\n",
    "})\n",
    "print('\\nComparison (first 10 rows of validation set):')\n",
    "print(comp)\n",
    "\n",
    "if os.path.exists(TEST_PATH):\n",
    "    df_test = pd.read_csv(TEST_PATH)\n",
    "\n",
    "    test_missing = [c for c in CONTINUOUS + CATEGORICAL if c not in df_test.columns]\n",
    "    if test_missing:\n",
    "        print('Warning: test file is missing columns:', test_missing)\n",
    "    else:\n",
    "        X_test = df_test[CONTINUOUS + CATEGORICAL].copy()\n",
    "        \n",
    "        for col in CONTINUOUS:\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].median())\n",
    "        for col in CATEGORICAL:\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].mode()[0])\n",
    "        \n",
    "        X_test_cat = pd.get_dummies(X_test[CATEGORICAL], drop_first=True)\n",
    "        \n",
    "        for c in cat_columns:\n",
    "            if c not in X_test_cat.columns:\n",
    "                X_test_cat[c] = 0\n",
    "        X_test_cat = X_test_cat[cat_columns]\n",
    "        \n",
    "        X_test_cont = scaler.transform(X_test[CONTINUOUS])\n",
    "        X_test_proc = np.hstack([X_test_cont, X_test_cat.values])\n",
    "        \n",
    "        y_test_log_pred = model.predict(X_test_proc)\n",
    "        y_test_pred = np.expm1(y_test_log_pred)\n",
    "        submission = pd.DataFrame({'Id': df_test['Id'], 'SalePrice': y_test_pred})\n",
    "        submission.to_csv('submission.csv', index=False)\n",
    "        print('Saved submission.csv (first 5 lines):')\n",
    "        print(submission.head())\n",
    "else:\n",
    "    print('\\nNo test.csv found in data/ — skipping submission cell.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af5008-eb16-4a82-9881-1a1b1c9228f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
